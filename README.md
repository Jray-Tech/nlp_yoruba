# ğŸ§  Englishâ€“Yoruba Language Classification & Translation

This project investigates **machine learning and deep learning models** for Englishâ€“Yoruba language processing. From traditional Naive Bayes classifiers to modern Transformer-based translation, it showcases a practical pipeline for low-resource language applications.

---

## ğŸ“Œ Project Overview

This notebook demonstrates how to:

- ğŸ”¤ **Classify** text as English or Yoruba using **Naive Bayes**.
- ğŸ§  **Cluster** semantically similar sentences with **K-Means on sentence embeddings**.
- ğŸ” Build a **sequence-to-sequence (seq2seq)** translation model using **RNN/LSTM**.
- ğŸŒ Fine-tune a **Transformer (e.g., mT5)** model for **neural machine translation**.
- ğŸ§ª Evaluate results with industry-standard metrics: **Accuracy**, **F1-score**, **BLEU**, **METEOR**, and **Silhouette Score**.

---

## ğŸ› ï¸ Technologies Used

- **Python**, **Scikit-learn**, **TensorFlow/Keras**, **Transformers (HuggingFace)**
- **NLTK**, **Pandas**, **Seaborn**, **Matplotlib**
- **sacreBLEU**, **rouge_score**, **sentencepiece**
- Pretrained GloVe embeddings for sentence vectorization

---

## ğŸ“Š Dataset

- File: `train.tsv`
- Structure: Parallel Englishâ€“Yoruba sentence pairs.
- Tasks include tokenization, length analysis, and vocabulary inspection.

---

## ğŸ§ª Evaluation Metrics

| Task                          | Evaluation Metric  |
| ----------------------------- | ------------------ |
| Classification                | Accuracy, F1-Score |
| Clustering                    | Silhouette Score   |
| Translation (RNN/Transformer) | BLEU, METEOR       |

---

## ğŸ“ Project Structure

```
â”œâ”€â”€ glove.6B.100d.txt         # Pretrained word vectors (downloaded)
â”œâ”€â”€ train.tsv                 # Parallel corpus for training
â”œâ”€â”€ AppliedAI.ipynb           # Main Jupyter Notebook
â””â”€â”€ README.md                 # Project summary (this file)
```

---

## ğŸš€ How to Run

1. Clone the repo and install dependencies:

   ```bash
   pip install pandas scikit-learn matplotlib seaborn nltk tensorflow transformers datasets sacrebleu rouge_score
   ```

2. Launch the notebook:

   ```bash
   jupyter notebook AppliedAI.ipynb
   ```

3. Follow the cells step-by-step to preprocess data, train models, and evaluate performance.

---

## ğŸ“ˆ Highlights

- Clean preprocessing pipeline for multilingual data
- Demonstrates **zero-shot** translation potential using multilingual models
- Applies both **symbolic ML** and **deep learning** to a real-world, low-resource language task

---

## ğŸ§  Author Notes

This work was part of a broader research initiative to support **low-resource language translation** and improve **NLP inclusivity** for African languages.
